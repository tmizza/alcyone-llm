### **ðŸš€ Extracting Learned Patterns from Your Trained Transformer Model**  

Now that weâ€™ve looked **inside the modelâ€™s weights**, letâ€™s extract **actual learned patterns** to see **what your model "knows."**  

This means analyzing:  
âœ” **Word similarity** (Are `"dog"` and `"puppy"` close in vector space?)  
âœ” **Attention patterns** (Which words get the most attention in a sentence?)  
âœ” **Neuron activations** (Which parts of the model respond most strongly to different inputs?)  

---

# **ðŸ“Œ Step 1: Load Your Modelâ€™s Embedding Matrix**
ðŸ’¡ **First, letâ€™s extract the raw word embeddings from the model.**  

Each token **has a learned vector representation** in the embedding matrix.

```python
import torch

# âœ… Load trained model weights
model_weights = torch.load("minigpt_final.pth")

# âœ… Extract token embeddings
token_embeddings = model_weights['token_embedding.weight']

# âœ… Print the shape of the embedding matrix
print("Embedding Matrix Shape:", token_embeddings.shape)  # Should be (VOCAB_SIZE, D_MODEL)

# âœ… Print the first 5 token embeddings
print("Sample embeddings:", token_embeddings[:5])
```
âœ” This will output something like:
```
Embedding Matrix Shape: torch.Size([50000, 1024])
Sample embeddings: 
tensor([
    [ 0.0245, -0.0312,  0.0158, ..., -0.0074],
    [ 0.0456,  0.0123, -0.0876, ...,  0.0012],
    [-0.0201,  0.0421,  0.0056, ..., -0.0234],
    ...
])
```
ðŸ’¡ **Each row represents a tokenâ€™s learned meaning in 1024-dimensional space.**

---

# **ðŸ“Œ Step 2: Find Similar Words in the Modelâ€™s Embedding Space**
ðŸ’¡ **Now, letâ€™s check if the model has learned real-world word relationships.**  
Weâ€™ll compare **word embeddings** to find **similar words**.

```python
import torch
import numpy as np

# âœ… Function to compute cosine similarity between word embeddings
def cosine_similarity(vec1, vec2):
    return torch.dot(vec1, vec2) / (torch.norm(vec1) * torch.norm(vec2))

# âœ… Compare two words
word_1_id = 100  # Example token ID for "dog"
word_2_id = 342  # Example token ID for "puppy"

similarity = cosine_similarity(token_embeddings[word_1_id], token_embeddings[word_2_id])
print(f"Cosine Similarity: {similarity.item()}")
```
âœ” If the model **trained well**, `"dog"` and `"puppy"` should have a high similarity score (closer to `1.0`).  

---

# **ðŸ“Œ Step 3: Analyze Attention Patterns**
ðŸ’¡ **Next, letâ€™s check which words a model focuses on when processing a sentence.**  

```python
# âœ… Extract self-attention weights from the first layer
attention_weights = model_weights['encoder_layers.0.self_attn.q_proj_weight']

# âœ… Print first 5 attention weights
print("Sample attention weights:", attention_weights[:5, :5])
```
âœ” This will show **how words interact** with each other in the first Transformer layer.

---

# **ðŸ“Œ Step 4: Find Which Neurons Activate Most for Specific Words**
ðŸ’¡ **Letâ€™s see which neurons (dimensions in 1024-space) respond most strongly to a word like `"happy"`**.

```python
# âœ… Extract token embedding for a specific word
word_id = 567  # Example token ID for "happy"
word_vector = token_embeddings[word_id]

# âœ… Print the top 5 highest values in the vector (most active neurons)
top_activations = torch.topk(word_vector, 5)
print(f"Top activations for 'happy': {top_activations}")
```
âœ” This tells us **which parts of the model "light up"** when the word `"happy"` is processed.

---

# **ðŸš€ Summary: What Your Model Has Learned**
âœ” **Your model stores every token as a 1024-dimension vector.**  
âœ” **Words with similar meanings are close together in vector space.**  
âœ” **Self-attention weights show which words influence each other the most.**  
âœ” **Some neurons specialize in different types of words (e.g., emotions, nouns, verbs).**  

ðŸš€ **You just extracted real knowledge from your model! Want to visualize embeddings with PCA?** ðŸ”¥ðŸ”¥ðŸ”¥